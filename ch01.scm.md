Building Abstractions with Procedures
=====================================

Exercise 1.2
------------

*Translate the following expression into prefix form*

![$ $\frac {5 + 4 + (2 - (3 - (6 + \frac {4} {5})))} {3(6 - 2)(2 - 7)}$ $](img/ex1.2.png?raw=true)

```scheme
(/ (+ 5 4 (- 2 (- 3 (+ 6 (/ 4 5)))))
   (* 3 (- 6 2) (- 2 7)))
```

Exercise 1.3
------------

*Define a procedure that takes three numbers as arguments and returns the sum
of the squares of the two larger numbers.*

```scheme
(define (ex1.3 x y z)
  (define (square x) (* x x))
  (define (max x y) (if (> x y) x y))
  (define (sum-of-squares x y) (+ (square x) (square y)))
  (if (> x y)
    (+ (sum-of-squares x (max y z)))
    (+ (sum-of-squares y (max x z)))))
```

Exercise 1.4
------------

*Describe the behaviour of the following procedure:*

    (define (a-plus-abs-b a b)
      ((if (> b 0) + -) a b))

This will add b to a if b is positive, otherwise it will subtract it.
In other words it adds the absolute value of b to a.

Exercise 1.5
------------

*Given the procedures:*

    (define (p) (p))
    (define (test x y)
      (if (= x 0)
        0
        y))

*What would be the result of running: (test 0 (p))?*

The answer is of course an infinite loop as it will attempt to evaluate the
value of (p) before calling the function (test) which discards it.  This is in
contrast to what would happen under normal-order (lazy) evaluation, in which
case the computation in the else branch of the if statement would never be run
and so (test 0 (p)) would simply return 0.

Exercise 1.6
------------

*What would happen if we attempted to use the following implementation to
compute square roots?*

    (define (new-if predicate then-clause else-clause)
      (cond (predicate then-clause)
            (else else-clause)))
    (define (sqrt-iter guess x)
      (new-if (good-enough? guess x)
              guess
              (sqrt-iter (improve guess x)
                         x)))

The answer is an infinite loop, for the same reasons as outlined above.

Exercise 1.7
------------

*Design a square-root procedure that stops when the change is a very small
fraction of the guess, rather than when the square of the guess is a small
number away from the required result.*

```scheme
(define (sqrt x)
  (define (good-enough? guess last-guess)
    (< (/ (abs (- guess last-guess))
          guess)
       0.001))

  (define (average x y)
    (/ (+ x y) 2))

  (define (improve guess x)
    (average guess (/ x guess)))

  (define (sqrt-iter guess last-guess x)
    (if (good-enough? guess last-guess)
      guess
      (sqrt-iter (improve guess x)
                 guess
                 x)))

  (sqrt-iter (improve 1.0 x) 1.0 x))
```

Exercise 1.8
------------

*Implement a cube-root procedure analogous to the square-root procedure.*

```scheme
(define (cbrt x)
  (define (good-enough? guess last-guess)
    (< (/ (abs (- guess last-guess))
          guess)
       0.001))

  (define (improve guess x)
    (/ (+ (/ x (square guess)) (* 2 guess))
       3))

  (define (cbrt-iter guess last-guess x)
    (if (good-enough? guess last-guess)
      guess
      (cbrt-iter (improve guess x)
                 guess
                 x)))

  (cbrt-iter (improve 1.0 x) 1.0 x))
```

Exercise 1.9
------------

*Using the substitution model, illustrate the process generated by each of the
following procedures in evaluating `(+ 4 5)`.  Are these processes iterative or
recursive?*

    (define (+ a b)
      (if (= a 0)
          b
          (inc (+ (dec a) b))))

    (define (+ a b)
      (if (= a 0)
          b
          (+ (dec a) (inc b))))

Here is the first one, which is recursive:

```
(+ 4 5)
(inc (+ 3 5))
(inc (inc (+ 2 5)))
(inc (inc (inc (+ 1 5))))
(inc (inc (inc (inc (+ 0 5)))))
(inc (inc (inc (inc 5))))
(inc (inc (inc 6)))
(inc (inc 7)
(inc 8)
9
```

And the second, which is iterative:

```
(+ 4 5)
(+ 3 6)
(+ 2 7)
(+ 1 8)
(+ 0 9)
9
```

Exercise 1.10
-------------

*The following procedure computes a mathematical function calles Ackermann's
function.*

```scheme
(define (A x y)
  (cond ((= y 0) 0)
        ((= x 0) (* 2 y))
        ((= y 1) 2)
        (else    (A (- x 1)
                    (A x (- y 1))))))
```

*What are the values of the following expressions? `(A 1 10)`, `(A 2 4)`,
`(A 3 3)`*

```
(A 1 10)
(A 0 (A 1 9))
(A 0 (A 0 (A 1 8)))
(A 0 (A 0 (A 0 (A 1 7))))
(A 0 (A 0 (A 0 (A 0 (A 1 6)))))
(A 0 (A 0 (A 0 (A 0 (A 0 (A 1 5))))))
(A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 1 4)))))))
(A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 1 3))))))))
(A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 1 2)))))))))
(A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 1 1))))))))))
(A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 2)))))))))
(A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 4))))))))
(A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 8)))))))
(A 0 (A 0 (A 0 (A 0 (A 0 (A 0 16))))))
(A 0 (A 0 (A 0 (A 0 (A 0 32)))))
(A 0 (A 0 (A 0 (A 0 64))))
(A 0 (A 0 (A 0 128)))
(A 0 (A 0 256))
(A 0 512)
1024
```

```
(A 2 4)
(A 1 (A 2 3))
(A 1 (A 1 (A 2 2)))
(A 1 (A 1 (A 1 (A 2 1))))
(A 1 (A 1 (A 1 2)))
(A 1 (A 1 (A 0 (A 1 1))))
(A 1 (A 1 (A 0 2)))
(A 1 (A 1 4))
(A 1 (A 0 (A 1 3)))
(A 1 (A 0 (A 0 (A 1 2))))
(A 1 (A 0 (A 0 (A 0 (A 1 1)))))
(A 1 (A 0 (A 0 (A 0 2))))
(A 1 (A 0 (A 0 4)))
(A 1 (A 0 8))
(A 1 16)
; ...(A 1 n) == 2ⁿ...
65536
```

```
(A 3 3)
(A 2 (A 3 2))
(A 2 (A 2 (A 3 1)))
(A 2 (A 2 2))
(A 2 (A 1 (A 2 1)))
(A 2 (A 1 2))
(A 2 (A 0 (A 1 1)))
(A 2 (A 0 2))
(A 2 4)
(A 1 (A 2 3))
(A 1 (A 1 (A 2 2)))
(A 1 (A 1 (A 1 (A 2 1))))
(A 1 (A 1 (A 1 2)))
(A 1 (A 1 4))
(A 1 16)
65536
```

*Give concise mathematical definitions for the functions computed by the
procedures `f`, `g`, and `h` below, given positive integer values of `n`.  For
example, `(k n)` computes 5n².*

```scheme
(define (f n) (A 0 n))
(define (g n) (A 1 n))
(define (h n) (A 2 n))
(define (k n) (* 5 n n))
```

![$ $f(n) = 2n$ $](img/ex1.10-1.png?raw=true)

![$ $g(n) = 2^n$ $](img/ex1.10-2.png?raw=true)

![$ $h(n) = 2^{2^n}$ $](img/ex1.10-3.png?raw=true)

Exercise 1.11
-------------

*A function `f` is defined by the rule that `f(n) = n` if `n < 3` and `f(n) =
f(n - 1) + 2f(n - 2) + 3f(n - 3)` if n ≥ 3.*

*Write a procedure that computes `f` by means of a recursive process.*

```scheme
(define (f n)
  (if (< n 3)
      n
      (+ (f (- n 1))
         (* 2 (f (- n 2)))
         (* 3 (f (- n 3))))))
```

*Write a procedure that computes `f` by means of an iterative process.*

```scheme
(define (f-iter a b c count)
  (if (= count 0)
    a
    (f-iter b
            c
            (+ c (* 2 b) (* 3 a))
            (- count 1))))

(define (f n)
  (f-iter 0 1 2 n))
```

Exercise 1.12
-------------

*Write a procedure that computes elements of Pascal's triangle by means of a
recursive process.*

```scheme
(define (pascals-triangle row index)
  (if (or (= index 1) (= index row))
      1
      (+ (pascals-triangle (- row 1) (- index 1))
         (pascals-triangle (- row 1) index))))
```

Note that this solution performs no bounds checking, so passing indices ≤ 0 or >
row won't work.

Exercise 1.13
-------------

*Prove that `Fib(n)` is the closest integer to `Φⁿ/√5`, where `Φ = (1 + √5)/2`.*

We are given that `Φ² = Φ + 1`, and we are also given the clue that another
number, `ψ = (1 - √5)/2` will be helpful in solving the problem.  It would be
useful to know whether the first property also holds for ψ, i.e. `ψ² = ψ + 1`.

![$
\minipage{1.0\textwidth}
\newtheorem*{lemma}{Lemma}
\begin{lemma}
$\psi^2 = \psi + 1$
\end{lemma}
\begin{proof}
The proof proceeds by simple algebraic substitution.
\begin{align*}
\psi^2 &= \frac{1 - \sqrt{5}}{2} \times \frac{1 - \sqrt{5}}{2} \\
       &= \frac{(1 - \sqrt{5})(1 - \sqrt{5})}{4}               \\
       &= \frac{6 - 2(\sqrt{5})}{4}                            \\
       &= \frac{3 - \sqrt{5}}{2} = \frac{2}{2} + \frac{1 - \sqrt{5}}{2} \\
       &= 1 + \psi && \qedhere
\end{align*}
\end{proof}
\endminipage
$](img/ex1.13-thm1.png?raw=true)

It does!  We can use this property of both Φ and ψ to show that `Φⁿ = Φⁿ⁻¹ +
Φⁿ⁻²`, a property which has parallels with the Fibonacci sequence.

![$
\minipage{1.0\textwidth}
\newtheorem*{lemma}{Lemma}
\begin{lemma}
$\phi^n = \phi^{n-1} + \phi^{n-2}$
\end{lemma}
\begin{proof}
\begin{align*}
\phi^n &= \phi \times \phi^{n-1} = \phi \times \phi \times \phi^{n-2} = \phi^2 \times \phi^{n-2} \\
       &= (\phi + 1) \times \phi^{n-2}  && \text{because $\phi^2 = \phi + 1$}                    \\
       &= \phi^{n-1} + \phi^{n-2}       && \qedhere
\end{align*}
\end{proof}
\endminipage
$](img/ex1.13-thm2.png?raw=true)

I have used Φ in the above calculation, but the proof is identical for ψ.

We now have all the tools we need to prove the assertion made in the text.

![$
\minipage{1.0\textwidth}
\newtheorem*{theorem}{Theorem}
\begin{theorem}
$Fib(n) = \frac{\phi^n - \psi^n}{\sqrt{5}}$
\end{theorem}
\begin{proof}
The proof proceeds by induction on $n$.
\begin{description}
\item[Base cases] \hfill \\
\begin{align*}
\phi^0 &= \frac{\phi^0 - \psi^0}{\sqrt{5}}                            \\
       &= \frac{1-1}{\sqrt{5}}                                        \\
       &= 0 = Fib(0)                                                  \\
\phi^1 &= \frac{\phi^1 - \psi^1}{\sqrt{5}}                            \\
       &= \frac{(1 + \sqrt{5})/2 - (1 - \sqrt{5})/2}{\sqrt{5}}        \\
       &= \frac{\frac{\sqrt{5}}{2} + \frac{\sqrt{5}}{2}}{\sqrt{5}}
        = \frac{\sqrt{5}}{\sqrt{5}}                                   \\
       &= 1 = Fib(1)                                                  \\
\end{align*}
\item[Inductive step] \hfill \\
Assuming the theorem holds for $n - 1$ and $n - 2$ we have:
\begin{align*}
\phi^n &= \frac{\phi^n - \psi^n}{\sqrt{5}}                            \\
       &= \frac{\phi^n}{\sqrt{5}} - \frac{\psi^n}{\sqrt{5}}           \\
       &= \frac{\phi^{n-2} - \psi^{n-2}}{\sqrt{5}} + \frac{\phi^{n-1} - \psi^{n-1}}{\sqrt{5}} \\
       &= Fib(n-2) + Fib(n-1)                                         \\
       &\therefore \text{the theorem holds for all $n$.} && \qedhere
\end{align*}
\end{description}
\end{proof}
\endminipage
$](img/ex1.13-thm3.png?raw=true)

By the time you've got this far you'd be forgiven for having forgotten what the
question was.  We can clearly see a strong relationship between Φ and the
Fibonacci sequence, but we're not quite there yet -- the question asks us to
prove that the *closest integer* to `Φⁿ/√5` is `Fib(n)`.  Let's use what we've
got so far to tackle that:

![$
\minipage{1.0\textwidth}
\newtheorem*{theorem}{Theorem}
\theoremstyle{definition}
\newtheorem*{definition}{Definition}
\begin{definition}
We can say that for any natural number $n$ and real number $x$, $n$ is the
closest integer to $x$ iff $|n - x| < \frac{1}{2}$.
\end{definition}
\begin{theorem}
The closest integer to $\phi^n/\sqrt{5}$ is $Fib(n)$
\end{theorem}
\begin{proof}
\begin{align*}
Fib(n)                             &= \frac{\phi^n - \psi^n}{\sqrt{5}} && \text{as shown above}\\
Fib(n) - \frac{\phi^n}{\sqrt{5}}   &= -\frac{\psi^n}{\sqrt{5}}                                 \\
\left|Fib(n) - \frac{\phi^n}{\sqrt{5}}\right| &= \left|\frac{\psi^n}{\sqrt{5}}\right|
  && \therefore \text{the theorem holds so long as $\left|\frac{\psi^n}{\sqrt{5}}\right| < \frac{1}{2}$} \\
\left|\frac{\psi^0}{\sqrt{5}}\right| &= \left|\frac{1}{\sqrt{5}}\right|    && < \frac{1}{2}  \\
\left|\frac{\psi^n}{\sqrt{5}}\right| &= \left|\frac{\psi \times \psi^{n-1}}{\sqrt{5}}\right|
  && \therefore \text{$\left|\frac{\psi^n}{\sqrt{5}}\right| < \frac{1}{2}$ for all $n$ in $\mathbb{N}$, since $|\psi| < 1$}
  \qedhere
\end{align*}
\end{proof}
\endminipage
$](img/ex1.13-thm4.png?raw=true)

Exercise 1.14
-------------

*Draw the tree illustrating the process generated by the `count-change`
procedure of section 1.2.2 in making change for 11 cents.*

![.
digraph cc {
  root             [label="cc 11 5"];  root -> l;                           root -> r;
  l                [label="cc 11 4"];  l -> ll;                             l -> lr;
  ll               [label="cc 11 3"];  ll -> lll;                           ll -> llr;
  lll              [label="cc 11 2"];  lll -> llll;                         lll -> lllr;
  llll             [label="cc 11 1"];  llll -> lllll;                       llll -> llllr;
  lllll            [label="cc 11 0"];  lllll -> lllllv;
  lllllv           [label="0",color=red];
  lr               [label="cc -14 4"]; lr -> lrv;
  lrv              [label="0",color=red];
  llr              [label="cc 1 3"];   llr -> llrl;                         llr -> llrr;
  llrl             [label="cc 1 2"];   llrl -> llrll;                       llrl -> llrlr;
  llrll            [label="cc 1 1"];   llrll -> llrlll;                     llrll -> llrllr;
  llrlll           [label="cc 1 0"];   llrlll -> llrlllv;
  llrlllv          [label="0",color=red];
  lllr             [label="cc 6 2"];   lllr -> lllrl;                       lllr -> lllrr;
  lllrl            [label="cc 6 1"];   lllrl -> lllrll;                     lllrl -> lllrlr;
  lllrll           [label="cc 6 0"];   lllrll -> lllrllv;
  lllrllv          [label="0",color=red];
  llllr            [label="cc 10 1"];  llllr -> llllrl;                     llllr -> llllrr;
  llllrl           [label="cc 10 0"];  llllrl -> llllrlv;
  llllrlv          [label="0",color=red];
  llllrr           [label="cc 9 1"];   llllrr -> llllrrl;                   llllrr -> llllrrr;
  llllrrl          [label="cc 9 0"];   llllrrl -> llllrrlv;
  llllrrlv         [label="0",color=red];
  llllrrr          [label="cc 8 1"];   llllrrr -> llllrrrl;                 llllrrr -> llllrrrr;
  llllrrrl         [label="cc 8 0"];   llllrrrl -> llllrrrlv;
  llllrrrlv        [label="0",color=red];
  llllrrrr         [label="cc 7 1"];   llllrrrr -> llllrrrrl;               llllrrrr -> llllrrrrr;
  llllrrrrl        [label="cc 7 0"];   llllrrrrl -> llllrrrrlv;
  llllrrrrlv       [label="0",color=red];
  llllrrrrr        [label="cc 6 1"];   llllrrrrr -> llllrrrrrl;             llllrrrrr -> llllrrrrrr;
  llllrrrrrl       [label="cc 6 0"];   llllrrrrrl -> llllrrrrrlv;
  llllrrrrrlv      [label="0",color=red];
  llllrrrrrr       [label="cc 5 1"];   llllrrrrrr -> llllrrrrrrl;           llllrrrrrr -> llllrrrrrrr;
  llllrrrrrrl      [label="cc 5 0"];   llllrrrrrrl -> llllrrrrrrlv;
  llllrrrrrrlv     [label="0",color=red];
  llllrrrrrrr      [label="cc 4 1"];   llllrrrrrrr -> llllrrrrrrrl;         llllrrrrrrr -> llllrrrrrrrr;
  llllrrrrrrrl     [label="cc 4 0"];   llllrrrrrrrl -> llllrrrrrrrlv;
  llllrrrrrrrlv    [label="0",color=red];
  llllrrrrrrrr     [label="cc 3 1"];   llllrrrrrrrr -> llllrrrrrrrrl;       llllrrrrrrrr -> llllrrrrrrrrr;
  llllrrrrrrrrl    [label="cc 3 0"];   llllrrrrrrrrl -> llllrrrrrrrrlv;
  llllrrrrrrrrlv   [label="0",color=red];
  llllrrrrrrrrr    [label="cc 2 1"];   llllrrrrrrrrr -> llllrrrrrrrrrl;     llllrrrrrrrrr -> llllrrrrrrrrrr;
  llllrrrrrrrrrl   [label="cc 2 0"];   llllrrrrrrrrrl -> llllrrrrrrrrrlv;
  llllrrrrrrrrrlv  [label="0",color=red];
  llllrrrrrrrrrr   [label="cc 1 1"];   llllrrrrrrrrrr -> llllrrrrrrrrrrl;   llllrrrrrrrrrr -> llllrrrrrrrrrrr;
  llllrrrrrrrrrrl  [label="cc 1 0"];   llllrrrrrrrrrrl -> llllrrrrrrrrrrlv;
  llllrrrrrrrrrrlv [label="0",color=red];
  llllrrrrrrrrrrr  [label="cc 0 1"];   llllrrrrrrrrrrr -> llllrrrrrrrrrrrv;
  llllrrrrrrrrrrrv [label="1",color=green];
  lllrr            [label="cc 1 2"];   lllrr -> lllrrl;                     lllrr -> lllrrr;
  lllrrl           [label="cc 1 1"];   lllrrl -> lllrrll;                   lllrrl -> lllrrlr;
  lllrrll          [label="cc 1 0"];   lllrrll -> lllrrllv;
  lllrrllv         [label="0",color=red];
  lllrrlr          [label="cc 0 1"];   lllrrlr -> lllrrlrv;
  lllrrlrv         [label="1",color=green];
  lllrlr           [label="cc 5 1"];   lllrlr -> lllrlrl;                   lllrlr -> lllrlrr;
  lllrlrl          [label="cc 5 0"];   lllrlrl -> lllrlrlv;
  lllrlrlv         [label="0",color=red];
  lllrlrr          [label="cc 4 1"];   lllrlrr -> lllrlrrl;                 lllrlrr -> lllrlrrr;
  lllrlrrl         [label="cc 4 0"];   lllrlrrl -> lllrlrrlv;
  lllrlrrlv        [label="0",color=red];
  lllrlrrr         [label="cc 3 1"];   lllrlrrr -> lllrlrrrl;               lllrlrrr -> lllrlrrrr;
  lllrlrrrl        [label="cc 3 0"];   lllrlrrrl -> lllrlrrrlv;
  lllrlrrrlv       [label="0",color=red];
  lllrlrrrr        [label="cc 2 1"];   lllrlrrrr -> lllrlrrrrl;             lllrlrrrr -> lllrlrrrrr;
  lllrlrrrrl       [label="cc 2 0"];   lllrlrrrrl -> lllrlrrrrlv;
  lllrlrrrrlv      [label="0",color=red];
  lllrlrrrrr       [label="cc 1 1"];   lllrlrrrrr -> lllrlrrrrrl;           lllrlrrrrr -> lllrlrrrrrr;
  lllrlrrrrrl      [label="cc 1 0"];   lllrlrrrrrl -> lllrlrrrrrlv;
  lllrlrrrrrlv     [label="0",color=red];
  lllrlrrrrrr      [label="cc 0 1"];   lllrlrrrrrr -> lllrlrrrrrrv;
  lllrlrrrrrrv     [label="1",color=green];
  lllrrr           [label="cc -4 2"];  lllrrr -> lllrrrv;
  lllrrrv          [label="0",color=red];
  llrr             [label="cc -9 3"];  llrr -> llrrv;
  llrrv            [label="0",color=red];
  llrlr            [label="cc -4 2"];  llrlr -> llrlrv;
  llrlrv           [label="0",color=red];
  llrllr           [label="cc 0 1"];   llrllr -> llrllrv;
  llrllrv          [label="1",color=green];
  r                [label="cc -39 5"]; r -> rv;
  rv               [label="0",color=red];
}
.](img/ex1.14.png?raw=true)

*What are the orders of growth of the space and number of steps used by this
process as the amount to be changed increases?*

Looking at the graph, we can see a pattern emerge: walking down the left side of
the graph a number of sub-graphs are formed as `kinds-of-coins` decreases.
Taking `kinds-of-coins == 1` as an example (we can ignore the `0` value because
that will always just return `0`), the sub-graph forms a fairly simple, spinal
shape until it reached `cc 0 1`, which returns `1` and signifies the end of
recursion.  This sub-graph is clearly Θ(n) in both time and space, and since
there is one for every kind of coin, we can say that the order of growth as the
amount to be changed increases is Θ(n⁵) in time and space, or more generally
Θ(nᵏ) where `k` is `kinds-of-coins`.

Exercise 1.15
-------------

*Consider the following procedure to approximate the sine of an angle:*

```scheme
(define (cube x) (* x x x))

(define (p x)
  (- (* 3 x) (* 4 (cube x))))

(define (sine angle)
   (if (not (> (abs angle) 0.1))
       angle
       (p (sine (/ angle 3.0)))))
```

*How many times is the procedure `p` applied when `(sine 12.15)` is evaluated?*

```
(p (sine 4.05))
(p (p (sine 1.35)))
(p (p (p (sine 0.45))))
(p (p (p (p (sine 0.15)))))
(p (p (p (p (p (sine 0.05))))))
```

So `p` will be applied five times.

*What is the order of growth in space and number of steps (as a function of `a`)
used by the process generated by the `sine` procedure when `(sine a)` is
evaluated?*

Again we have a recursive procedure so the order of growth in space and the
number of steps will be the same.  In this case a new recursive
call is introduced every time `a` is tripled, which we call Θ(log a).

Exercise 1.16
-------------

*Design a procedure that evolves an iterative exponentiation process that uses
successive squaring and uses a logarithmic number of steps, as does
`fast-expt`.*

Let's start off by reviewing the recursive implementation of `fast-expt` given
in the text:

```scheme
(define (even? n)
  (= (remainder n 2) 0))

(define (fast-expt b n)
  (cond ((= n 0) 1)
        ((even? n) (square (fast-expt b (/ n 2))))
        (else (* b (fast-expt b (- n 1))))))
```

The problem of making this iterative, then, is to try and turn the recursive
calls to `fast-expt` into tail calls.  We have two recursive calls to consider
here: the second and third branches of the `cond` statement.  The text basically
gives us the answer to the first one by pointing out the observation:

![$ $(b^{n/2})^2 = (b^2)^{n/2}$ $](img/ex1.16.png?raw=true)

which means that it can be rewritten in a tail-recursive manner as follows:

```
(fast-expt (square b) (/ n 2))
```

The second part is trickier.  In the case of an odd `n`, we need to multiply the
result of the process by `b`, but how do we do this in a tail-recursive style?
The answer is to move the result into a parameter, resulting in the following
iterative implementation:

```scheme
(define (fast-expt-iter b n a)
  (cond ((= n 0)   a)
        ((even? n) (fast-expt-iter (square b) (/ n 2) a))
        (else      (fast-expt-iter b          (- n 1) (* a b)))))
```

Where you pass `1` as the initial parameter to `a`.  We don't really want this
implementation detail leaking out, so let's wrap `fast-expt-iter` in a
convenience function to make its API match `fast-expt`.

```scheme
(define (fast-expt b n)
  (fast-expt-iter b n 1))
```

Exercise 1.17
-------------

*Consider the following multiplication procedure, analogous to the `expt`
procedure considered earlier:*

```
(define (* a b)
  (if (= b 0)
      0
      (+ a (* a (- b 1)))))
```

*This algorithm takes a number of steps that is linear in `b`.  Now suppose we
include the following two procedures to double and halve integers:*

```scheme
(define (double x) (* x 2))
(define (halve x)
  (if (even? x)
      (/ x 2)
      (error "halve can only be run on even values! not" x)))
```

*Using these, design a multiplication procedure analogous to fast-expt that uses
a logarithmic number of steps.*

The overall shape of this procedure ends up exactly the same as `fast-expt`; we
simply replace `square` with `double`, `*` with `+`, and `(/ b 2)` with `(halve
b)` (which means the same thing anyway).  Finally since we are using addition to
represent a multiplication rather than multiplication to represent raising to a
power, our base case needs to be changed to the identity for addition, namely
`0`.  The resulting procedure is as follows:

```scheme
(define (fast-* a b)
  (cond ((= b 0) 0)
        ((even? b) (double (fast-* a (halve b))))
        (else (+ a (fast-* a (- b 1))))))
```

Exercise 1.18
-------------

*Using the results of exercises 1.16 and 1.17 devise a procedure that generates
an iterative process for multiplying two integers in terms of adding, doubling,
and halving and uses a logarithmic number of steps.*

As with the last answer, we can take `fast-expt-iter` and perform the same
substitutions to arrive at `fast-*-iter`.

```scheme
(define (fast-*-iter a b i)
  (cond ((= b 0) i)
        ((even? b) (fast-*-iter (double a) (halve b) i))
        (else (fast-*-iter a (- b 1) (+ a i)))))
```

And as before, we'll provide a convenience function to call it, passing the
identity for addition as the initial value for `i`.

```scheme
(define (fast-* a b)
  (fast-*-iter a b 0))
```

Exercise 1.19
-------------

*Complete the following procedure, which calculates numbers from the fibonacci
sequence in a logarithmic number of steps*

> Rather than write out the procedure twice, once with my completions and once
> without, it is written out in full at the end of the answer.

The text reminds us of the transformation

![$
\minipage{0.3\textwidth}
\begin{align*}
T = & a \leftarrow a + b \\
    & b \leftarrow a
\end{align*}
\endminipage
$](img/ex1.19-1.png?raw=true)

which can be considered a special case of the following, more general
transformation:

![$
\minipage{0.3\textwidth}
\begin{align*}
T_{pq} = & a \leftarrow bq + aq + ap \\
         & b \leftarrow bp + aq
\end{align*}
\endminipage
$](img/ex1.19-2.png?raw=true)

for the case when *p* = 0 and *q* = 1.  We can compose these transformations
together by feeding the output of the first transformation into the input of the
second.  We can see the result of this by substituting the result of the
transformation for the values of *a* and *b* in the transformation itself, ie:

![$
\minipage{0.7\textwidth}
\begin{align*}
T_{pq} \cdot T_{pq} = & a \leftarrow (bp + aq)q + (bq + aq + ap)q + (bq + aq + ap)p \\
                      & b \leftarrow (bp + aq)p + (bq + aq + ap)q
\end{align*}
\endminipage
$](img/ex1.19-3.png?raw=true)

If we can rearrange these equations to arrive at values for *p* and *q* which
will plug into the original transformation, we will have a new transformation
which represents the composition of this transformation with itself; in other
words its "square".  Doing so is a matter of simple algorithmic substitution:

![$
\minipage{0.7\textwidth}
\begin{align*}
a & \leftarrow (bp + aq)q + (bq + aq + ap)q + (bq + aq + ap)p \\
  & = (bpq + a(q^2)) + (b(q^2) + a(q^2) + apq) + (bpq + apq + a(p^2)) \\
  & = 2bpq + 2apq + 2a(q^2) + a(p^2) + b(q^2) \\
  & = b(2pq + q^2) + a(2pq + q^2) + a(p^2 + q^2) \\
b & \leftarrow (bp + aq)p + (bq + aq + ap)q \\
  & = b(p^2) + aqp + b(q^2) + a(q^2) + apq \\
  & = b(p^2 + q^2) + a(2pq + q^2) \\
  & \therefore T_{pq} \cdot T_{pq} = T_{p'q'}\text{, where}\\
p' & = p^2 + q^2 \\
q' & = 2pq + q^2
\end{align*}
\endminipage
$](img/ex1.19-4.png?raw=true)

Substituting these values into the provided procedure we arrive at the complete
version below.

```scheme
(define (fib n)
  (fib-iter 1 0 0 1 n))
(define (fib-iter a b p q count)
  (cond ((= count 0) b)
        ((even? count)
         (fib-iter a
                   b
                   (+ (square p) (square q))
                   (+ (* 2 p q) (square q))
                   (/ count 2)))
        (else (fib-iter (+ (* b q) (* a q) (* a p))
                        (+ (* b p) (* a q))
                        p
                        q
                        (- count 1)))))
```

Exercise 1.20
-------------

*Using the substitution method (for normal order), illustrate the process
generated in evaluating `(gcd 206 40)` and indicate the `remainder` operations
that are actually performed.*

For reference, here is the `gcd` method from the text:

```scheme
(define (gcd a b)
  (if (= b 0)
      a
      (gcd b (remainder a b))))
```

The evaluation rule for `if` forces evaluation of its argument, in order to
determine which branch to walk, so this procedure will be expanded as follows:

```
(gcd 206 40)

(if (= 40 0)
  206
  (gcd 40 (remainder 206 40)))

(if (= 40 0)
  206
  (if (= 6 0) ; Forced evaluation of (remainder 206 40)
    40
    (gcd (remainder 206 40) (remainder 40 (remainder 206 40)))))

(if (= 40 0)
  206
  (if (= 6 0)
    40
    (if (= 4 0) ; Forced evaluation of (remainder 40 (remainder 206 40))
      (remainder 206 40)
      (gcd (remainder 40 (remainder 206 40))
           (remainder (remainder 206 40)
                      (remainder 40 (remainder 206 40)))))))

(if (= 40 0)
  206
  (if (= 6 0)
    40
    (if (= 4 0)
      (remainder 206 40)
      (if (= 2 0) ; Forced evaluation of (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))
        (remainder 40 (remainder 206 40))
        (gcd (remainder (remainder 206 40)
                        (remainder 40 (remainder 206 40)))
             (remainder (remainder 40 (remainder 206 40))
                        (remainder (remainder 206 40)
                                   (remainder 40 (remainder 206 40)))))))))

(if (= 40 0)
  206
  (if (= 6 0)
    40
    (if (= 4 0)
      (remainder 206 40)                  ; never evaluated
      (if (= 2 0)
        (remainder 40 (remainder 206 40)) ; never evaluated
        (if (= 0 0) ; Forced evaluation of (remainder (remainder 40 (remainder 206 40))
                    ;                                 (remainder (remainder 206 40)
                    ;                                            (remainder 40 (remainder 206 40))))
            (remainder (remainder 206 40)
                       (remainder 40 (remainder 206 40)))
                    ; The following monster is never evaluated
            (gcd (remainder (remainder 40 (remainder 206 40))
                            (remainder (remainder 206 40)
                                       (remainder 40 (remainder 206 40))))
                 (remainder (remainder (remainder 206 40)
                                       (remainder 40 (remainder 206 40)))
                            (remainder (remainder 40 (remainder 206 40))
                                       (remainder (remainder 206 40)
                                                  (remainder 40 (remainder 206 40)))))))))))
```

Following the `if`s to get the final value which will be evaluated and returned
for `gcd 206 40` gives us:

```
(remainder (remainder 206 40)
           (remainder 40 (remainder 206 40)))
```

Which involves four calls to `remainder`, in addition to the fourteen calls
whose evaluation was forced by their being used as part in the `if` special
form.  The total number of calls to `remainder`, then, is eighteen.  In an
applicative order evaluator, the total number of calls to `remainder` would be
four (once for each call to `gcd` except the last).

In reality, in a real non-strict language like Haskell, the thunk representing
the call to remainder would be replaced with the actual value when it is first
evaluated, so the number of calls to `remainder` would be four, the same as an
applicative order evaluator.  The difference then would not be the number of
calls, but when (and if) those calls are made.

Exercise 1.21
-------------

*Use the following procedure to find the smallest divisor of each of the
following numbers: 199, 1999, 19999.*

```scheme
(define (smallest-divisor n)
  (find-divisor n 2))
(define (find-divisor n test-divisor)
  (cond ((> (square test-divisor) n) n)
        ((divides? test-divisor n) test-divisor)
        (else (find-divisor n (+ test-divisor 1)))))
(define (divides? a b)
  (= (remainder b a) 0))
```

```
(smallest-divisor 199)
;Value: 199

(smallest-divisor 1999)
;Value: 1999

(smallest-divisor 19999)
;Value: 7
```

Exercise 1.22
-------------

*The following `timed-prime-test` procedure, when called with an integer `n`,
prints `n` and checks to see if `n` is prime.  If `n` is prime, the procedure
prints three asterisks followed by the amount of time used in performing the
test.*

```scheme
(define (timed-prime-test n)
  (newline)
  (display n)
  (start-prime-test n (runtime)))
(define (start-prime-test n start-time)
  (if (prime? n)
      (report-prime (- (runtime) start-time))))
(define (prime? n)
  (= n (smallest-divisor n)))
(define (report-prime elapsed-time)
  (display " *** ")
  (display elapsed-time))
```

*Using this procedure, write a procedure `search-for-primes` that checks the
primality of consecutive odd integers in a specified range.*

```scheme
(define (search-for-primes start end)
  (cond ((even? start) (search-for-primes (+ start 1) end))
        ((< start end) (timed-prime-test start)
                        (search-for-primes (+ start 2) end))))
```

*Use your procedure to find the three smallest primes larger than 1000;*

```
(search-for-primes 1000 1050)

; 1009 *** 0.
; 1013 *** 0.
; 1019 *** 0.
```

*larger than 10000;*

```
(search-for-primes 10000 10050)

; 10007 *** 0.
; 10009 *** 0.
; 10037 *** 0.
```

*larger than 100000;*

```
(search-for-primes 100000 100500)

100003 *** 0.
100019 *** 0.
100043 *** 0.
```

*larger than 1000000.*

```
(search-for-primes 1000000 1000500)

1000003 *** 0.
1000033 *** 9.999999999999787e-3
1000037 *** 0.
```

*Note the time needed to test each prime.*

These times are all far too small to be of any value at all; I guess that's the
book showing its age.  I'm going to try with some bigger numbers; but first,
let's modify the above functions so that we can search for the next three prime
numbers, rather than all prime numbers within a range.  This way I don't need to
pick arbitrary values for the second parameter.  First, `start-prime-test` needs
to return true or false depending on whether the number was prime:

```scheme
(define (start-prime-test n start-time)
  (let ((n-is-prime? (prime? n)))
    (if n-is-prime?
        (report-prime (- (runtime) start-time)))
    n-is-prime?))
```

And then `search-for-primes` can be modified to take the number of primes you
want as its second parameter:

```scheme
(define (search-for-primes start count)
  (cond ((even? start) (search-for-primes (+ start 1) count))
        ((> count 0)   (search-for-primes (+ start 2)
                                          (if (timed-prime-test start)
                                              (- count 1)
                                              count)))))
```

We can now look for the first three primes after any number:

```
(search-for-primes 1000000000 3)

1000000007 *** .05999999999999872
1000000009 *** .0600000000000005
1000000021 *** .0600000000000005

(search-for-primes 10000000000 3)

10000000019 *** .17999999999999972
10000000033 *** .16999999999999993
10000000061 *** .17999999999999972

(search-for-primes 100000000000 3)

100000000003 *** .5599999999999987
100000000019 *** .5400000000000009
100000000057 *** .5400000000000009

(search-for-primes 1000000000000 3)

1000000000039 *** 1.7199999999999989
1000000000061 *** 1.7599999999999998
1000000000063 *** 1.7300000000000004
```

OK, these look like some numbers we can work with!  Let's carry on.

*Since the testing algorithm has order of growth of `Θ(√n)`, you should expect
that testing for primes around 10000000000 should take about √10 times as long
as testing for primes around 1000000000.  Do your timing data bear this out?
How well do the data for 10000000000 and 100000000000 support the √n
prediction?*

Taking a very rough average of the figures above, the timings for 10000000000
are around 0.175 as opposed to 0.055 for timings around 1000000000.  This is a
difference of around 3.18 times, which is quite close to √10.  Moving up a step
, timings around 100000000000 average about 0.545, which is about 3.11 times
0.175.  This also seems fairly close -- it's a little off, but we can probably
chalk that up to inaccurate timings / spurious effects (other processes, etc).
Finally taking the timings for numbers around 100000000000 gives us around 1.73,
which is 3.17 times 0.545 -- again, close enough to √10.

Exercise 1.23
-------------

*Define a procedure `next` that returns 3 if the input is equal to 2 and
otherwise returns its input plus 2.  Modify the `smallest-divisor` procedure to
use `(next test-divisor)` instead of `(+ test-divisor 1)`.*

```scheme
(define (next n)
  (if (= n 2) 3 (+ n 2)))

(define (find-divisor n test-divisor)
  (cond ((> (square test-divisor) n) n)
        ((divides? test-divisor n) test-divisor)
        (else (find-divisor n (next test-divisor)))))
```

*With `timed-prime-test` incorporating this modified version of
`smallest-divisor`, run the test for each of the 12 primes found in exercise
1.22.  Since this modification halves the number of test steps, you should
expect it to run about twice as fast.  Is this expectation confirmed?  If not,
what is the observed ratio of the speeds of the two algorithms, and how do you
explain the fact that it is different from 2?*

```
(timed-prime-test 1000000000063)
;1000000000063 *** 1.120000000000001

(timed-prime-test 1000000000061)
;1000000000061 *** 1.1099999999999994

(timed-prime-test 1000000000039)
;1000000000039 *** 1.1099999999999994

(timed-prime-test 100000000057)
;100000000057 *** .39000000000000057

(timed-prime-test 100000000019)
;100000000019 *** .36999999999999744

(timed-prime-test 100000000003)
;100000000003 *** .3500000000000014

(timed-prime-test 1000000021)
;1000000021 *** .03999999999999915

(timed-prime-test 1000000009)
;1000000009 *** .03999999999999915

(timed-prime-test 1000000007)
;1000000007 *** .03999999999999915
```

The ratio averages at around 1.5, so substantially less than 2.  Some part of
the benefit of reducing the number of calls to `find-divisor` is offset by the
fact that we have had to introduce calls to `(next n)` in their place, which
performs an if and, usually, an addition.  In fact, since we add a call to
`next` for every call to `find-divisor`, we have essentially replaced half our
calls to `find-divisor` with a call to `next`.  This gives us quite good returns
as `next` is cheaper than `find-divisor`; but it isn't free.  The cost of
calling `next` explains the discrepancy seen.

Exercise 1.24
-------------

*Modify the `timed-prime-test` procedure of exercise 1.22 to use `fast-prime?`
(the Fermat method), and test each of the primes you found in that exercise.*

Here is the Fermat method from the text:

```scheme
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder (square (expmod base (/ exp 2) m))
                    m))
        (else
         (remainder (* base (expmod base (- exp 1) m))
                    m))))

(define (fermat-test n)
  (define (try-it a)
    (= (expmod a n n) a))
  (try-it (+ 1 (random (- n 1)))))

(define (fast-prime? n times)
  (cond ((= times 0) true)
        ((fermat-test n) (fast-prime? n (- times 1)))
        (else false)))
```

Modifying `start-prime-test` to use it is pretty simple.  We need to choose a
number of times to run the test; I'm going to rather arbitrarily assign it to
1000 here.  I'm using my modified version of the function here, which returns
the result, so that I can pass in the number of primes that I want rather than
the range.

```scheme
(define (start-prime-test n start-time)
  (let ((n-is-prime? (fast-prime? n 1000)))
    (if n-is-prime?
        (report-prime (- (runtime) start-time)))
    n-is-prime?))
```

Here are results using the Fermat test version of the procedure:

```
(for-each timed-prime-test (list 1000000000063 1000000000061 1000000000039
                                 100000000057  100000000019  100000000003
                                 1000000021    1000000009    1000000007))

;1000000000063 *** .16000000000000014
;1000000000061 *** .16000000000000014
;1000000000039 *** .14999999999999858
;100000000057 *** .15000000000000213
;100000000019 *** .14999999999999858
;100000000003 *** .15000000000000213
;100000000019 *** .16000000000000014
;1000000021 *** .11999999999999744
;1000000009 *** .10999999999999943
;1000000007 *** .120000000000001
```

The numbers have got a bit small again, so let's just grab a few more data
points with higher numbers:

```
(search-for-primes 10000000000000000000000000000000000000000000000 3)
;10000000000000000000000000000000000000000000121 *** .6799999999999997
;10000000000000000000000000000000000000000000537 *** .6799999999999997
;10000000000000000000000000000000000000000000603 *** .6700000000000017
```

Exercise 1.25
-------------

*Would the following procedure be a suitable replacement for `expmod` above?
Explain.*

```
(define (expmod base exp m)
  (remainder (fast-expt base exp) m))
```

Let's take a look!

```
(timed-prime-test 10007)
; 10007 *** 9.64
```

That would be a no.  9.64 seconds to perform a calculation that was too fast
even to time before.  The reason for this is actually documented in the text;
buried in footnote 46.  This, more naïve `expmod` implementation generates mch
bigger numbers only to throw them away when it does the modulus operation, which
has a large impact on performance.
